<p align="center">
  <a href="#о-репрезитории">О репрезитории</a> •
  <a href="#данные">Данные</a> •
  <a href="#моделирование">Моделирование</a> •
  <a href="#пайплайн">Пайплайн</a> •
  <a href="#лицензия">Лицензия</a>
</p>

<p align="center">
<a href="https://github.com/Blinorot/pytorch_project_template/blob/main/LICENSE">
   <img src=https://img.shields.io/badge/license-MIT-blue.svg>
</a>
</p>

## О репрезитории

Данный репозиторий содержит реализацию семантического анализа твитов о COVID-19.

Данная задача была выбрана в рамках учебного проекта по MLOps. Ставится попытка
построения модели семантического анализа текста (в данном случае твитов) в
условиях постоянно обновляющихся данных и меняющихся внешних обстоятельств.
Читателю нужно представить, что сейчас только самое начало пандемии.

**Контекст:**

Пользователи Twitter активно обсуждают тему COVID-19, однако из-за глобальности
и опасности неправильного толкования ситуации (наведение паники) руководству
необходимо отслеживать семантическое "настроение" текстов, которые пишут
пользователи. Руководству необходимо иметь полную картину общественного мнения
по этой ситуации, чтобы не допускать обострения негативного влияния на поведение
людей и вовремя реагировать на проблемы, возникающие в связи с обсуждением темы.
Команда дата-аналитиков уже проанализировала некоторую часть твитов для того,
чтобы можно было обучить модель (классифицировала). Однако этих данных
недостаточно, и данные будут постоянно поступать от тех, кто размечает данные.
Для ускорения разметки решили применить метод Human Feedback. Этот метод
позволяет человеку анализировать семантику твита не с нуля, а принимая во
внимание ответ базовой модели. Если он не согласен с ответом базовой модели, то
он ставит свое правильное значение.

Также важная предпосылка, что у компании нет больших серверов, мощностей, а
также времени, для того, чтобы обучать сложные трансформерные модели. Модель
нужно дообучать на данных буквально каждые 15–30 минут.

**Задача:**

Построить систему, основанную на модели семантической классификации твитов
пользователей по COVID-19, которую можно быстро переобучать на новых данных.

## Структура проекта

```bash
.
├── commands.py
├── covid_tweet_analysis
│   ├── constants.py
│   ├── data
│   │   ├── Corona_NLP_test.xls
│   │   ├── Corona_NLP_train.csv
│   │   └── Corona_NLP_train_short.csv
│   ├── embeddings_model.py
│   ├── infer.py
│   ├── __init__.py
│   ├── models
│   │   └── model.txt
│   ├── test.py
│   └── train.py
├── docker-compose.yml
├── Dockerfile
├── LICENSE
├── poetry.lock
├── pyproject.toml
└── README.md

```

## Данные

В качестве данных был выбран собранный набор твитов
[Coronavirus tweets NLP - Text Classification](https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification?select=Corona_NLP_train.csv),
который будет использоваться постепенно, чтобы создать ситуацию, при которой у
нас поступают новые данные, на которых мы хотели бы дообучать модель, чтобы она
давала более хорошие прогнозы. В данных есть особенности: они содержат исходный
текст твита, который необходимо очищать от синтаксического мусора (ответ на
чей-то твит, ссылка на YouTube-видео и т.д.), а также от различных пропусков в
самих данных. Всего имеется около 45 000 твитов, что является достаточно большим
количеством для обучения хорошей модели, и это соответствует контексту задачи.

## Моделирование

Для обеспечения _высокого качества_ модели классификации текста и _быстрого
дообучения_ используется подход обучения градиентного бустинга на эмбеддингах. В
качестве модели эмбеддингов используется мультиязычная модель
[jina-embeddings-v3](https://huggingface.co/jinaai/jina-embeddings-v3), которая
знает более 30 языков и показывает лучшие результаты на
[MTEB](https://huggingface.co/spaces/mteb/leaderboard). В качестве модели
градиентного бустинга используется
[LightGBM](https://lightgbm.readthedocs.io/en/stable/), так как она имеет
высокое качество и минимальную скорость обучения.

Библиотеки для моделей: pandas, lightgbm

Библиотека для развертывания эмбеддингов:
[infinity](https://michaelfeil.eu/infinity/0.0.70/)

## Пайплайн

Продакшн-пайплайн выглядит следующим образом:

Тексты твитов проходят через модель эмбеддингов, которая расположена в
Docker-контейнере на сервере. Градиентный бустинг обучается на эмбеддингах
твитов. Далее, когда поступают новые данные, модель дообучается по тому же
принципу на новых данных. Если качество модели повысилось, она занимает место
предшественницы. Для настройки правильного дообучения модели по времени
предположительно будет использоваться Airflow.

## Лицензия

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE)
